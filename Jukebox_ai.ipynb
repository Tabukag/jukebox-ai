{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jukebox ai",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNqchO2WqlA0DptnvPyzF8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tabukag/jukebox-ai/blob/master/Jukebox_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSGfzHB5UkFV",
        "colab_type": "code",
        "outputId": "d8cdef08-6d7d-491e-f912-54b93dff3094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "!pip install git+https://github.com/openai/jukebox.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/jukebox.git\n",
            "  Cloning https://github.com/openai/jukebox.git to /tmp/pip-req-build-tusiv72h\n",
            "  Running command git clone -q https://github.com/openai/jukebox.git /tmp/pip-req-build-tusiv72h\n",
            "Requirement already satisfied (use --upgrade to upgrade): jukebox==1.0 from git+https://github.com/openai/jukebox.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: fire==0.1.3 in /usr/local/lib/python3.6/dist-packages (from jukebox==1.0) (0.1.3)\n",
            "Requirement already satisfied: tqdm==4.45.0 in /usr/local/lib/python3.6/dist-packages (from jukebox==1.0) (4.45.0)\n",
            "Requirement already satisfied: soundfile==0.10.3.post1 in /usr/local/lib/python3.6/dist-packages (from jukebox==1.0) (0.10.3.post1)\n",
            "Requirement already satisfied: unidecode==1.1.1 in /usr/local/lib/python3.6/dist-packages (from jukebox==1.0) (1.1.1)\n",
            "Requirement already satisfied: numba==0.48.0 in /usr/local/lib/python3.6/dist-packages (from jukebox==1.0) (0.48.0)\n",
            "Requirement already satisfied: librosa==0.7.2 in /usr/local/lib/python3.6/dist-packages (from jukebox==1.0) (0.7.2)\n",
            "Requirement already satisfied: mpi4py>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from jukebox==1.0) (3.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire==0.1.3->jukebox==1.0) (1.12.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile==0.10.3.post1->jukebox==1.0) (1.14.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.48.0->jukebox==1.0) (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba==0.48.0->jukebox==1.0) (1.18.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.48.0->jukebox==1.0) (46.3.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (2.1.8)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.22.2.post1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1->jukebox==1.0) (2.20)\n",
            "Building wheels for collected packages: jukebox\n",
            "  Building wheel for jukebox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jukebox: filename=jukebox-1.0-cp36-none-any.whl size=197563 sha256=c2e35757c810811a378143ee9c14830b3d66c65c917469c482c55b146e771cf8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d16apgd1/wheels/bd/b6/f9/ad38a67dd989a522bbe6677e95efbc4607cdcf71e7249485fe\n",
            "Successfully built jukebox\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zboBbZwAVKhR",
        "colab_type": "code",
        "outputId": "73c2697a-d3ff-47c2-b17c-bea3ef4810a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9FEWEodVKw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "026f3bbb-eca3-49c9-9726-6746ce3bd879"
      },
      "source": [
        "model = \"5b_lyrics\" # or \"1b_lyrics\"     \n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = 3 if model=='5b_lyrics' else 8\n",
        "hps.name = 'samples'\n",
        "chunk_size = 16 if model==\"5b_lyrics\" else 32\n",
        "max_batch_size = 3 if model==\"5b_lyrics\" else 16\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = [.5,.5,.125]\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading from gce\n",
            "Restored from /root/.cache/jukebox-assets/models/5b/vqvae.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Loading artist IDs from /usr/local/lib/python3.6/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.6/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:2, Cond downsample:None, Raw to tokens:128, Sample length:1048576\n",
            "0: Converting to fp16 params\n",
            "Downloading from gce\n",
            "Restored from /root/.cache/jukebox-assets/models/5b_lyrics/prior_level_2.pth.tar\n",
            "0: Loading prior in eval mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9hdIdWEVK6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_length_in_seconds = 157"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_biCb_RjVLEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjCkjxCYVLO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metas = [dict(artist = \"The Weeknd\",\n",
        "            genre = \"R&B\",\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = \"\"\"\n",
        "gotta keep it going for the promo \n",
        "said to keep our kisses for the low though\n",
        "Im just tryna get out of the friendzone\n",
        "cause you look even better than your photos\n",
        "gotta find your house, send me the info\n",
        "driving through the gated residential\n",
        "you love I was coming, sent your friends home \n",
        "if you wanna hide let your friends know \n",
        "\n",
        "I only want you when it's past the night \n",
        "the only time when it feels right\n",
        "i only want you to hold me not feel me \n",
        "Keep it fucked up for the real me\n",
        "when im fucked up thats the real me yeah\n",
        "I only want you when it's past the night \n",
        "the only time when it feels right\n",
        "i only want you to hold me not feel me \n",
        "Keep it fucked up for the real me\n",
        "when im fucked up can't you see me babe\n",
        "\n",
        "When you gonna tell me keep it simple\n",
        "I only keep it up to keep it simple\n",
        "I fucked two more bitches just to warn you\n",
        "never gonna slow this fucking tempo\n",
        "always wanna send me off to rehab\n",
        "when im just living for this fucking moment\n",
        "and you really want a fucking real love\n",
        "\n",
        "I only want you when it's past the night \n",
        "the only time when it feels right\n",
        "i only want you to hold me not feel me \n",
        "Keep it fucked up for the real me\n",
        "when im fucked up thats the real me yeah\n",
        "I only want you when it's past the night \n",
        "the only time when it feels right\n",
        "i only want you to hold me not feel me \n",
        "Keep it fucked up for the real me\n",
        "when im fucked up can't you see me babe\n",
        "\n",
        "            \"\"\",\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5ADsQeLW7C7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampling_temperature = .98\n",
        "\n",
        "lower_batch_size = 16\n",
        "max_batch_size = 3 if model == \"5b_lyrics\" else 16\n",
        "lower_level_chunk_size = 32\n",
        "chunk_size = 16 if model == \"5b_lyrics\" else 32\n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKcHxeTMW8BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMZDHup0W8NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Audio(f'{hps.name}/level_2/item_0.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiB4O0g9G79v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if True:\n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8AxrMgbRKK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls {checkpoint_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB26TpB-Rkfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}